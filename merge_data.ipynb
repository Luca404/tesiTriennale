{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c357b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c2adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = \"R3000\"\n",
    "\n",
    "#Carico tutti i dati\n",
    "prices = pd.read_csv( f\"./data/data{INDEX}/all_prices_D.csv\" )\n",
    "shorts = pd.read_csv( f\"./data/data{INDEX}/all_short_interest.csv\" )\n",
    "news = pd.read_csv( f\"./data/data{INDEX}/all_news_volume_D.csv\" )\n",
    "\n",
    "tickers = pd.read_csv( f\"./data/data{INDEX}/all_tickers_filtered.csv\" )[\"ticker\"].unique()\n",
    "prices = prices[prices[\"ticker\"].astype(str).isin([str(t) for t in tickers])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendo i prices alla data degli shorts\n",
    "prices = prices.copy()\n",
    "shorts = shorts.copy()\n",
    "\n",
    "prices[\"ticker\"] = prices[\"ticker\"].astype(str)\n",
    "shorts[\"ticker\"] = shorts[\"ticker\"].astype(str)\n",
    "\n",
    "prices[\"date\"] = pd.to_datetime(prices[\"date\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "shorts[\"date\"] = pd.to_datetime(shorts[\"date\"],  errors=\"coerce\").dt.tz_localize(None)\n",
    "\n",
    "prices = prices.dropna(subset=[\"ticker\",\"date\"])\n",
    "shorts = shorts.dropna(subset=[\"ticker\",\"date\"])\n",
    "\n",
    "prices = prices[prices[\"ticker\"].isin([str(t) for t in tickers])].copy()\n",
    "shorts = shorts[shorts[\"ticker\"].isin([str(t) for t in tickers])].copy()\n",
    "\n",
    "left = (shorts[[\"ticker\",\"date\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values(\"date\", kind=\"mergesort\")           \n",
    "        .reset_index(drop=True))\n",
    "\n",
    "right = (prices[[\"ticker\",\"date\",\"close\"]]\n",
    "         .sort_values(\"date\", kind=\"mergesort\")             \n",
    "         .reset_index(drop=True))\n",
    "\n",
    "prices_on_short = pd.merge_asof(\n",
    "    left=left,\n",
    "    right=right,\n",
    "    on=\"date\",            \n",
    "    by=\"ticker\",               \n",
    "    direction=\"backward\",\n",
    "    allow_exact_matches=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2290aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prendo il numero di news alla data degli shorts (calcolati dallo shorts precedente allo shorts attuale)\n",
    "\n",
    "shorts[\"date\"] = pd.to_datetime(shorts[\"date\"], errors=\"coerce\").dt.tz_localize(None).dt.floor(\"D\")\n",
    "news[\"date\"]  = pd.to_datetime(news[\"date\"],  errors=\"coerce\", utc=True).dt.tz_convert(None).dt.floor(\"D\")\n",
    "shorts = shorts.dropna(subset=[\"ticker\",\"date\"]).reset_index(drop=True)\n",
    "news  = news.dropna(subset=[\"ticker\",\"date\"]).reset_index(drop=True)\n",
    "shorts = shorts.sort_values([\"ticker\",\"date\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "shorts[\"prev_date\"] = shorts.groupby(\"ticker\")[\"date\"].shift(1)\n",
    "news = news.sort_values([\"ticker\",\"date\"], kind=\"mergesort\").reset_index(drop=True)\n",
    "news[\"cum_news\"] = news.groupby(\"ticker\")[\"news_count\"].cumsum()\n",
    "\n",
    "left_curr  = shorts[[\"ticker\",\"date\"]].sort_values(\"date\", kind=\"mergesort\").reset_index(drop=True)\n",
    "right_curr = news[[\"ticker\",\"date\",\"cum_news\"]].sort_values(\"date\", kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "curr = pd.merge_asof(\n",
    "    left=left_curr,\n",
    "    right=right_curr,\n",
    "    on=\"date\",\n",
    "    by=\"ticker\",\n",
    "    direction=\"backward\",\n",
    "    allow_exact_matches=True\n",
    ").rename(columns={\"cum_news\":\"cum_curr\"})\n",
    "\n",
    "prev_left = (\n",
    "    shorts[[\"ticker\",\"prev_date\"]]\n",
    "    .dropna(subset=[\"prev_date\"])\n",
    "    .rename(columns={\"prev_date\":\"date_left\"})\n",
    "    .sort_values(\"date_left\", kind=\"mergesort\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "right_prev = news[[\"ticker\",\"date\",\"cum_news\"]].sort_values(\"date\", kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "prev = pd.merge_asof(\n",
    "    left=prev_left,\n",
    "    right=right_prev,\n",
    "    left_on=\"date_left\",\n",
    "    right_on=\"date\",\n",
    "    by=\"ticker\",\n",
    "    direction=\"backward\",\n",
    "    allow_exact_matches=True\n",
    ").rename(columns={\"cum_news\":\"cum_prev\"})[[\"ticker\",\"date_left\",\"cum_prev\"]]\n",
    "\n",
    "news_window = (\n",
    "    curr\n",
    "    .merge(shorts[[\"ticker\",\"date\",\"prev_date\"]], on=[\"ticker\",\"date\"], how=\"left\")\n",
    "    .merge(prev, left_on=[\"ticker\",\"prev_date\"], right_on=[\"ticker\",\"date_left\"], how=\"left\")\n",
    "    .assign(\n",
    "        cum_curr=lambda d: d[\"cum_curr\"].fillna(0),\n",
    "        cum_prev=lambda d: d[\"cum_prev\"].fillna(0),\n",
    "        news_since_prev_short=lambda d: (d[\"cum_curr\"] - d[\"cum_prev\"]).astype(\"int64\")\n",
    "    )[[\"ticker\",\"date\",\"news_since_prev_short\"]]\n",
    "    .sort_values([\"ticker\",\"date\"], kind=\"mergesort\")\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e05ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unisco price con shorts\n",
    "df_merged = (\n",
    "    prices_on_short\n",
    "      .merge(shorts.rename(columns={\"volume\": \"si_volume\"}),\n",
    "             on=[\"ticker\",\"date\"], how=\"left\")\n",
    "      .sort_values([\"ticker\",\"date\"])\n",
    "      .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unisco anche news\n",
    "df_merged = (\n",
    "    df_merged.merge(news_window, on=[\"ticker\",\"date\"], how=\"left\")\n",
    "         .assign(news_since_prev_short=lambda d: d[\"news_since_prev_short\"].fillna(0).astype(\"int64\"))\n",
    "         .sort_values([\"ticker\",\"date\"])\n",
    "         .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a3a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sistemo df finale\n",
    "df_merged = df_merged.drop(columns=[\"prev_date\"])\n",
    "df_merged = df_merged.dropna().sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "df_merged = df_merged[[\"date\",\"ticker\", *[c for c in df_merged.columns if c not in (\"date\",\"ticker\")]]]\n",
    "df_merged.columns = [\"date\", \"ticker\", \"close\", \"d2c\", \"shorts\", \"volume\", \"news_volume\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e7a701f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv( \"./data/dataR3000/merged_data.csv\", index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
